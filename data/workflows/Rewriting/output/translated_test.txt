首先，我要说的是，这篇文章并不是对LLMs的回顾。很明显，2023年对于人工智能来说是特殊的一年，再重申这一点似乎没有意义。相反，这篇文章旨在作为一名个体程序员的见证。自从ChatGPT问世，以及后来使用本地运行的LLMs，我已经广泛地利用了这项新技术。目标是加速我的编程能力，但这并不是唯一的目的。还有一个意图是不把精力浪费在编程中不值得付出努力的方面。无数小时花在寻找关于奇特、智力上无趣方面的文档；努力学习一个过于复杂的API，往往没有充分的理由；编写几小时后就会丢弃的立即可用的程序。这些都是我不想做的事情，尤其是现在，谷歌已经变成了一个充满垃圾信息的海洋，要在其中寻找一些有用的东西。

与此同时，我在编程方面绝对不是新手。我有能力在没有任何帮助的情况下编写代码，实际上，我经常这样做。随着时间的推移，我越来越多地使用LLMs编写高级代码，尤其是在Python中，而在C语言中则较少。关于我个人使用LLMs的经验，让我印象深刻的是，我已经学会了何时使用它们，以及何时使用它们只会拖慢我的速度。我还了解到，LLMs有点像维基百科和YouTube上散布的所有视频课程：它们帮助那些有意愿、能力和纪律的人，但对那些落后的人来说，它们的好处微乎其微。我担心，至少在一开始，它们只会让那些已经具有优势的人受益。
同样地，我需要一个程序来读取AirBnB的CSV报告，并按月份和年份对我的公寓进行分组。然后，考虑到清洁成本和每次预订的晚数，它将对一年中不同月份的平均租金价格进行统计。这个程序对我来说非常有用。与此同时，编写它却极其乏味：没有什么有趣的地方。所以我从CSV文件中找了一个很好的部分，然后在GPT4上进行了复制粘贴。我向LLM写明了需要解决的问题：程序在第一次尝试时就成功运行了。我将完整的程序展示在下面。
```python
import pandas as pd
pd.set_option('display.max_rows', None)
df = pd.read_csv('listings.csv')
reservations = df[df['Type'] == 'Reservation']
reservations['Start Date'] = pd.to_datetime(reservations['Start Date'])
reservations['Year'] = reservations['Start Date'].dt.year
reservations['Month'] = reservations['Start Date'].dt.month
reservations['Nightly Rate'] = (reservations['Amount'] - reservations['Cleaning Fee']) / reservations['Nights']
all_listings = reservations['Listing'].unique()
all_years = reservations['Year'].unique()
all_months = range(1, 13)
index = pd.MultiIndex.from_product([all_listings, all_years, all_months], names=['Listing', 'Year', 'Month'])
all_data = pd.DataFrame(index=index).reset_index()
merged_data = pd.merge(all_data, reservations, on=['Listing', 'Year', 'Month'], how='left')
average_nightly_rates = merged_data.groupby(['Listing', 'Year', 'Month'])['Nightly Rate'].mean().fillna(0)
print(average_nightly_rates)
```
要准确理解如何对这些原本相当分散和无序的数据进行分组，需要一些简单的推理：这不是一个LLM可以通过简单地重复它所见过的类似语言来解决的问题。GPT4在其训练过程中肯定观察到了类似的程序，但几乎可以肯定的是，它没有见过需要以我要求的方式进行分组，并且在具有特定格式的CSV文件中进行分组的程序。这表明（在我看来），LLM在一定程度上可以在训练集中不同程序所勾勒出的空间内进行插值。

在我看来，编写这种类型的程序将是对我的时间的不谨慎使用。LLM能够为我完成这项工作无疑加快了我以相当直接的方式编写代码的能力：我可以专注于真正重要的事情。

以下是输出结果：
```c
#include <stdio.h>
#include <stdlib.h>
#include <string.h>
#include <math.h>

#define N 100000  // Number of elements
#define P 0.05    // False positive probability
#define M (int)(-(N * log(P)) / (log(2) * log(2)))  // Size of bit array
#define K (int)(M / N * log(2))  // Number of hash functions

unsigned char bitArray[M / 8 + 1];

void setBit(int n) {
    bitArray[n / 8] |= 1 << (n % 8);
}

int getBit(int n) {
    return bitArray[n / 8] & (1 << (n % 8));
}

// Basic hash functions (for demonstration purposes)
int hash1(char *str) {
    int hash = 5381;
    int c;
    while ((c = *str++))
        hash = ((hash << 5) + hash) + c;
    return abs(hash % M);
}

int hash2(char *str) {
    unsigned long hash = 0;
    int c;
    while ((c = *str++))
        hash = c + (hash << 6) + (hash << 16) - hash;
    return abs(hash % M);
}

void add(char *str) {
    setBit(hash1(str));
    setBit(hash2(str));
    // Add more hash functions if needed
}

int is_in(char *str) {
    return getBit(hash1(str)) && getBit(hash2(str));
    // Check more hash functions if used
}

int main() {
    char *testStr = "testString";
    add(testStr);

    if (is_in(testStr)) {
        printf("%s is probably in the set.\n", testStr);
    } else {
        printf("%s is definitely not in the set.\n", testStr);
    }

    return 0;
}
```
GPT4生成的实现并不是特别出色。布隆过滤器相当普遍，它并不是一种非常奇特的数据结构。然而，很明显，编写一个像样的布隆过滤器需要更强的抽象能力：例如，存在着如何找到一种有效的方法来对同一个字符串进行N次哈希，以及确保这些哈希值足够不相关的问题。

然而，如果你明确要求GPT4修改哈希函数，使其产生N个不相关的输出，它提出的解决方案会显著地更加可接受：
```c
unsigned int hash(const char* str, unsigned int hash_id) {
    unsigned int hash = 5381;
    int c;
    while ((c = *str++)) {
        hash = ((hash << 5) + hash) + c + hash_id;
    }
    return hash % BF_SIZE;
}
```
如果它自己想出了这个主意，它会以不同的方式编写布隆过滤器，使用单个哈希函数一次设置K个位。
