视频生成模型作为世界模拟器
我们探讨了在视频数据上进行大规模训练的生成模型。具体来说，我们在不同时长、分辨率和纵横比的视频和图像上联合训练文本条件扩散模型。我们利用了一个在视频和图像潜在代码的时空块上操作的变压器架构。我们最大的模型，Sora，能够生成一分钟的高保真视频。我们的结果表明，扩展视频生成模型是构建通用物理世界模拟器的有前景的途径。
这篇技术报告主要关注我们将各种类型的视觉数据转化为统一表示的方法，这种表示能够实现大规模的生成模型训练，以及（2）对Sora的能力和局限性进行定性评估。本报告中不包括模型和实现细节。
以前的许多研究已经使用各种方法研究了视频数据的生成建模，包括循环网络、生成对抗网络、自回归变换器和扩散模型。这些工作通常关注视觉数据的狭窄类别、较短的视频或固定大小的视频。Sora是一种通用的视觉数据模型——它可以生成不同持续时间、宽高比和分辨率的视频和图像，最多可生成一分钟的高清视频。
将视觉数据转换为图像块
我们从大型语言模型中汲取灵感，这些模型通过在互联网规模的数据上进行训练来获得通用能力。大型语言模型（LLM）范式的成功在一定程度上得益于使用能够优雅地统一多种文本形式（代码、数学和各种自然语言）的标记。在这项工作中，我们考虑如何让视觉数据的生成模型继承这些优势。与LLM具有文本标记不同，Sora具有视觉贴片。之前的研究已经证明，贴片是一种用于视觉数据模型的有效表示。我们发现，贴片是一种高度可扩展且有效的表示方法，可用于在多种类型的视频和图像上训练生成模型。
在高层次上，我们通过首先将视频压缩到一个低维潜在空间，然后将表示分解为时空片段，从而将视频转换为片段。
视频压缩网络
我们训练了一个降低视觉数据维度的网络。这个网络将原始视频作为输入，输出一个在时间和空间上都被压缩的潜在表示。Sora 在这个压缩的潜在空间中进行训练，并随后生成视频。我们还训练了一个相应的解码器模型，将生成的潜在表示映射回像素空间。
时空潜在补丁
给定一个压缩后的输入视频，我们提取一系列时空区块作为变换器的标记。这种方案也适用于图像，因为图像只是具有单个帧的视频。我们基于区块的表示方法使得Sora能够在具有不同分辨率、持续时间和纵横比的视频和图像上进行训练。在推理时，我们可以通过将随机初始化的区块排列在适当大小的网格中来控制生成视频的大小。
将变压器扩展到视频生成
Sora是一个扩散模型；给定输入的噪声补丁（以及诸如文本提示之类的条件信息），它被训练用于预测原始的“干净”补丁。重要的是，Sora是一个扩散变换器。变换器在各种领域展示出了显著的扩展性能，包括语言建模、计算机视觉和图像生成。
在这项工作中，我们发现扩散变换器在作为视频模型时也能有效地扩展。下面，我们展示了一个在固定种子和输入的情况下，随着训练进度的进行，视频样本的比较。随着训练计算的增加，样本质量显著提高。
可变时长、分辨率、宽高比
过去的图像和视频生成方法通常会将视频调整为标准尺寸，例如，将视频调整为256x256分辨率的4秒视频。我们发现，相反地，在原始尺寸上进行训练可以带来几个好处。
采样灵活性
Sora 可以处理宽屏 1920x1080p 视频、竖屏 1080x1920 视频以及介于两者之间的所有视频。这使得 Sora 能够直接为不同设备创建内容，保持其原生的宽高比。这也使我们能够在生成全分辨率内容之前，快速使用相同的模型对低分辨率内容进行原型设计。
改善构图与组
我们从实证研究中发现，在保持原始宽高比的视频上进行训练可以提高画面构图和取景效果。我们将Sora与我们的另一个模型版本进行比较，该版本将所有训练视频裁剪成正方形，这在训练生成模型时是常见的做法。在正方形裁剪的模型（左侧）中，有时会生成只有部分主体在画面中的视频。相比之下，Sora生成的视频（右侧）具有更好的取景效果。
语言理解
训练文本到视频生成系统需要大量带有相应文本标题的视频。我们将DALL·E 3中引入的重新标注技术应用于视频。首先，我们训练一个高度描述性的标题生成模型，然后用它为训练集中的所有视频生成文本标题。我们发现，在高度描述性的视频标题上进行训练可以提高文本的保真度以及视频的整体质量。
与DALL·E 3类似，我们也利用GPT将用户的简短提示转化为更长、更详细的描述，然后发送给视频模型。这使得Sora能够生成高质量的视频，准确地遵循用户的提示。
使用图像和视频进行提示
以上所有结果以及我们的登录页面都展示了文本到视频的样本。但是，Sora还可以通过其他输入进行提示，例如预先存在的图像或视频。这种功能使Sora能够执行广泛的图像和视频编辑任务——创建完美循环的视频，为静态图像添加动画，向前或向后延伸视频时间等。
为DALL·E图像制作动画
Sora能够根据输入的图像和提示生成视频。下面我们展示了基于DALL·E 2和DALL·E 3图像生成的示例视频。
扩展生成的视频
Sora同样具有延长视频的功能，无论是向前还是向后。下面是四个视频，它们都是从生成的视频片段开始向后延长的。因此，这四个视频的开头各不相同，但它们都通向相同的结局。
我们可以使用这种方法来向前和向后扩展视频，以制作一个无缝的无限循环。
视频到视频编辑
扩散模型已经使得从文本提示编辑图像和视频的方法层出不穷。在下面，我们将其中一种方法，SDEdit，应用于Sora。这种技术使得Sora能够在零射程内转换输入视频的风格和环境。
连接视频
我们还可以使用Sora在两个输入视频之间逐渐插值，从而在完全不同的主题和场景构成的视频之间创建无缝过渡。在下面的示例中，中间的视频在左侧和右侧对应的视频之间进行插值。
图像生成能力
Sora还具有生成图像的能力。我们通过在具有一个帧的时间范围的空间网格中排列高斯噪声块来实现这一点。该模型可以生成不同尺寸的图像——最高分辨率可达2048x2048。
新兴的仿真能力
我们发现，当进行大规模训练时，视频模型会表现出许多有趣的自发能力。这些能力使得Sora能够模拟现实世界中的人、动物和环境的某些方面。这些特性并没有任何关于3D、物体等方面的明确归纳偏见——它们纯粹是规模现象。
3D一致性。Sora能够生成具有动态摄像机运动的视频。随着摄像机的移动和旋转，人物和场景元素在三维空间中保持一致地移动。
长程一致性和物体恒存性。在生成长视频时，保持时间一致性一直是视频生成系统面临的重大挑战。我们发现Sora通常（尽管并非总是）能够有效地模拟短程和长程依赖关系。例如，我们的模型可以在人、动物和物体被遮挡或离开画面时保持它们的存在。同样，它可以在单个样本中生成同一角色的多个镜头，并在整个视频中保持他们的外观。
与世界互动。Sora有时可以模拟以简单方式影响世界状态的动作。例如，画家可以在画布上留下随着时间持续存在的新笔触，或者一个人可以吃掉一个汉堡并留下咬痕。
模拟数字世界。Sora 还能模拟人工过程——一个例子是视频游戏。Sora 可以在同时控制 Minecraft 中的玩家执行基本策略的同时，以高保真度呈现世界及其动态。只需通过在提示 Sora 时提及“Minecraft”，就可以零基础地调用这些功能。
这些能力表明，继续扩展视频模型是朝着开发高度能力的物理和数字世界模拟器的有前景的道路，以及生活在其中的物体、动物和人类。
讨论
Sora 目前作为一个模拟器存在许多局限性。例如，它并不能准确地模拟许多基本相互作用的物理过程，如玻璃破碎。其他相互作用，如吃食物，也并不总是产生正确的物体状态变化。我们在我们的登录页面中列举了模型的其他常见故障模式，例如在长时间样本中出现的不一致性或物体的自发出现。
我们相信，Sora目前所具备的能力表明，继续扩展视频模型是一条有前景的道路，有助于发展能够模拟物理和数字世界的高效模拟器，以及其中的物体、动物和人类。
