---
题目：生成动态场景的长视频
作者：Tim Brooks, Janne Hellsten, Miika Aittala, Ting-Chun Wang, Timo Aila, Jaakko Lehtinen, Ming-Yu Liu, Alexei A. Efros, Tero Karras
摘要：我们提出了一个视频生成模型，可以准确地再现物体运动、摄像机视角的变化以及随时间产生的新内容。现有的视频生成方法通常无法在保持真实环境中预期的一致性（如合理的动态和物体持续性）的同时，随时间产生新内容。一个常见的失败案例是由于过度依赖归纳偏差来提供时间一致性，例如一个单一的潜在代码决定整个视频的内容，导致内容永远不会发生变化。在另一个极端情况下，如果没有长期一致性，生成的视频可能会在不同的场景之间不现实地变形。为了解决这些局限性，我们通过重新设计时间潜在表示并通过在更长的视频上进行训练来从数据中学习长期一致性。为此，我们利用了两阶段训练策略，分别在低分辨率的长视频和高分辨率的短视频上进行训练。为了评估我们模型的能力，我们引入了两个新的基准数据集，专注于长期时间动态。
---