---
题目：生成具有场景动态的视频
作者：Carl Vondrick，Hamed Pirsiavash，Antonio Torralba
摘要：我们利用大量未标记的视频来学习场景动态模型，以便用于视频识别任务（如动作分类）和视频生成任务（如未来预测）。我们提出了一种具有时空卷积结构的视频生成对抗网络，该结构可以将场景的前景与背景分离。实验表明，该模型可以比简单基线更好地生成长达一秒的全帧速率的微小视频，并且我们展示了其在预测静态图像的合理未来方面的实用性。此外，实验和可视化表明，该模型在最小监督下内部学习识别动作的有用特征，表明场景动态是一种有前景的表示学习信号。我们相信生成视频模型可以影响视频理解和模拟的许多应用。
---