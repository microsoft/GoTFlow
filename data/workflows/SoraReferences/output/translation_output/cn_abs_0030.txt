---
题目：通过更好的图像描述提高图像生成质量
作者：James Betker, James Betker, Li Jing, Tim Brooks, Jianfeng Wang, Linjie Li, Long Ouyang, Juntang Zhuang, Joyce Lee, Yufei Guo, Wesam Manassra, Prafulla Dhariwal, Casey Chu, Yunxin Jiao, Aditya Ramesh
摘要：我们证明了通过在高度描述性的生成图像标题上进行训练，可以显著提高文本到图像模型的提示跟随能力。现有的文本到图像模型在遵循详细的图像描述方面存在困难，通常会忽略单词或混淆提示的含义。我们假设这个问题源于训练数据集中的噪声和不准确的图像标题。为解决这个问题，我们训练了一个定制的图像标题生成器，并用它重新生成训练数据集的标题。然后，我们训练了几个文本到图像模型，并发现在这些合成标题上进行训练可以可靠地提高提示跟随能力。最后，我们利用这些发现构建了DALL-E 3：一个新的文本到图像生成系统，并在一个旨在衡量提示跟随、一致性和美学的评估中对其性能进行基准测试，发现它与竞争对手相比具有优势。我们发布了这些评估的样本和代码，以便未来的研究可以继续优化文本到图像系统的这一重要方面。
---