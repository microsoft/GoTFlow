---
题目：像素生成预训练
作者：陈马克，雷德福德，瑞文·查尔德，吴杰，骆禾，普拉富拉·达里瓦尔，卢安·大卫，伊利亚·苏茨克维尔
摘要：受到自然语言无监督表示学习进展的启发，我们研究类似的模型是否可以为图像学习有用的表示。我们训练一个序列Transformer来自动回归地预测像素，而不需要结合二维输入结构的知识。尽管在没有标签的低分辨率ImageNet上进行训练，我们发现GPT-2规模的模型通过线性探测、微调和低数据分类来学习强大的图像表示。在CIFAR-10上，我们通过线性探测实现了96.3%的准确率，超过了监督的Wide ResNet，并通过完全微调实现了99.0%的准确率，与顶级监督预训练模型相匹配。一个在ImageNet和网络图像混合数据上训练的更大模型在ImageNet上与自监督基准竞争，通过我们特征的线性探测实现了72.0%的top-1准确率。
---