题目：MoCoGAN：将运动和内容分解用于视频生成
作者：Sergey Tulyakov, Ming-Yu Liu, Xiaodong Yang, Jan Kautz
摘要：视频中的视觉信号可以分为内容和运动。内容指定了视频中的对象，而运动描述了它们的动态。基于这个先验，我们提出了一种用于视频生成的运动和内容分解生成对抗网络（MoCoGAN）框架。所提出的框架通过将一系列随机向量映射到一系列视频帧来生成视频。每个随机向量包括内容部分和运动部分。在保持内容部分固定的同时，将运动部分实现为随机过程。为了在无监督的情况下学习运动和内容的分解，我们引入了一种新颖的对抗学习方案，利用图像和视频鉴别器。在几个具有挑战性的数据集上进行的广泛实验结果，以及与最先进方法的定性和定量比较，验证了所提出框架的有效性。此外，我们还展示了MoCoGAN允许生成具有相同内容但不同运动的视频，以及具有不同内容和相同运动的视频。