题目：对齐潜在变量：使用潜在扩散模型进行高分辨率视频合成
作者：Andreas Blattmann, Robin Rombach, Huan Ling, Tim Dockhorn, Seung Wook Kim, Sanja Fidler, Karsten Kreis
摘要：潜在扩散模型（LDMs）通过在压缩的低维潜在空间中训练扩散模型，实现高质量图像合成，同时避免过多的计算需求。在这里，我们将LDM范式应用于高分辨率视频生成，这是一项特别消耗资源的任务。我们首先仅在图像上预训练一个LDM；然后，通过在潜在空间扩散模型中引入时间维度，并在编码的图像序列（即视频）上进行微调，将图像生成器变为视频生成器。类似地，我们将扩散模型上采样器在时间上对齐，将它们变成具有时间一致性的视频超分辨率模型。我们关注两个相关的现实世界应用：模拟野外驾驶数据和通过文本到视频建模的创意内容创建。特别是，我们在分辨率为512 x 1024的真实驾驶视频上验证了我们的视频LDM，实现了最先进的性能。此外，我们的方法可以轻松利用现成的预训练图像LDM，因为在这种情况下，我们只需要训练一个时间对齐模型。通过这样做，我们将公开可用的最先进的文本到图像LDM稳定扩散转变为一种高效且富有表现力的文本到视频模型，分辨率可达1280 x 2048。我们证明了以这种方式训练的时间层可以推广到不同的微调文本到图像LDM。利用这一特性，我们展示了个性化文本到视频生成的第一个结果，为未来内容创建开辟了令人兴奋的方向。