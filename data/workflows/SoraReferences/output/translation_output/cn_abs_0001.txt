题名：使用LSTM对视频表示进行无监督学习
作者：Nitish Srivastava，Elman Mansimov，Ruslan Salakhutdinov
摘要：我们使用多层长短时记忆（LSTM）网络来学习视频序列的表示。我们的模型使用一个编码器LSTM将输入序列映射到一个固定长度的表示。这个表示使用单个或多个解码器LSTM进行解码以执行不同的任务，例如重构输入序列或预测未来序列。我们尝试两种输入序列 - 图像像素块和使用预训练卷积网络提取的视频帧的高级表示（“感知”）。我们探讨了不同的设计选择，例如解码器LSTM是否应该基于生成的输出。我们从定性的角度分析模型的输出，以了解模型如何将学到的视频表示推广到未来和过去。我们尝试可视化和解释学到的特征。我们通过在更长的时间尺度和领域外数据上运行模型来对其进行压力测试。我们进一步通过对UCF-101和HMDB-51数据集上的人类动作识别进行微调来评估表示。我们证明了这些表示有助于提高分类准确性，尤其是在只有少量训练样本的情况下。即使是在与任务无关的数据集（YouTube视频的300小时）上预训练的模型也可以帮助提高动作识别性能。