这几篇论文主要关注了使用扩散模型进行视频数据的生成建模。它们的共性主题是利用扩散模型生成高质量、高分辨率的视频内容。

第10篇论文提出了一种名为Imagen Video的文本条件视频生成系统，该系统基于一系列视频扩散模型。给定一个文本提示，Imagen Video通过基本视频生成模型和一系列交错的空间和时间视频超分辨率模型生成高清视频。文章还探讨了如何将系统扩展为高清文本到视频模型，包括选择在某些分辨率下的全卷积时间和空间超分辨率模型，以及扩散模型的v参数化选择。此外，文章还将扩散模型在图像生成方面的研究成果应用到视频生成领域。

第11篇论文将潜在扩散模型（LDM）应用于高分辨率视频生成。首先，在仅图像上预训练LDM，然后通过在潜在空间扩散模型中引入时间维度并在编码图像序列上进行微调，将图像生成器转换为视频生成器。同时，将扩散模型上采样器在时间上对齐，将其转换为具有时间一致性的视频超分辨率模型。文章关注了两个实际应用：模拟野外驾驶数据和文本到视频建模的创意内容创建。特别是，文章验证了在分辨率为512 x 1024的真实驾驶视频上的Video LDM，取得了最先进的性能。

第12篇论文提出了一种名为W.A.L.T的基于变换器的方法，通过扩散建模实现了逼真的视频生成。该方法有两个关键设计决策：首先，使用因果编码器将图像和视频压缩到统一的潜在空间中，实现跨模态的训练和生成；其次，为了内存和训练效率，采用了一种针对联合空间和时空生成建模的窗口注意力架构。这些设计决策使得在已建立的视频（UCF-101和Kinetics-600）和图像（ImageNet）生成基准上实现了最先进的性能，而无需使用分类器自由引导。最后，文章还训练了一个由基本潜在视频扩散模型和两个视频超分辨率扩散模型组成的模型级联，用于生成分辨率为512×896、每秒8帧的文本到视频生成任务。

总之，这些参考论文在Sora模型训练中的作用主要是利用扩散模型生成高质量、高分辨率的视频内容，为视频生成领域提供了有力的支持。