这几篇论文的共性主题是：将视频数据压缩到低维潜在空间以进行建模。

19. 高分辨率图像合成与潜在扩散模型
作者：Robin Rombach, Andreas Blattmann, Dominik Lorenz, Patrick Esser, Björn Ommer
摘要：通过将图像生成过程分解为去噪自动编码器的顺序应用，扩散模型（DMs）在图像数据及其他方面实现了最先进的合成结果。此外，它们的公式允许在不重新训练的情况下引导图像生成过程。然而，由于这些模型通常直接在像素空间中操作，优化强大的DMs通常需要数百个GPU天，而且由于顺序评估，推理成本很高。为了在有限的计算资源上进行DM训练，同时保留其质量和灵活性，我们将它们应用于强大的预训练自动编码器的潜在空间。与以前的工作相比，训练扩散模型在这样的表示上首次达到了复杂性降低和细节保留之间的近乎最优点，极大地提高了视觉保真度。通过在模型架构中引入交叉注意力层，我们将扩散模型变成了强大且灵活的生成器，用于处理一般条件输入，如文本或边界框，并以卷积方式实现高分辨率合成。我们的潜在扩散模型（LDMs）在图像修复方面实现了新的最先进水平，并在各种任务上取得了高度竞争性能，包括无条件图像生成、语义场景合成和超分辨率，同时与基于像素的DMs相比显著降低了计算要求。

结合这些参考论文，我们可以看出，在Sora模型训练中，这些论文主要起到了将视频数据压缩到低维潜在空间以进行建模的作用。这种方法使得Sora模型能够在有限的计算资源上进行训练，同时保留其质量和灵活性。通过在模型架构中引入交叉注意力层，Sora模型能够处理一般条件输入，如文本或边界框，并以卷积方式实现高分辨率合成。这些论文在图像修复、无条件图像生成、语义场景合成和超分辨率等任务上取得了高度竞争性能，为Sora模型的训练提供了有力的支持。