这几篇论文的共性主题是基于变换器架构的图像生成和文本到图像生成。

1. 《Generative Pretraining from Pixels》一文中，作者受到自然语言无监督表示学习的启发，研究了类似的模型是否可以为图像学习有用的表示。他们训练了一个序列变换器，自回归地预测像素，而不考虑2D输入结构的知识。尽管在低分辨率的ImageNet上进行无标签训练，但他们发现GPT-2规模的模型可以学习到强大的图像表示。

2. 《Zero-Shot Text-to-Image Generation》一文中，作者提出了一种基于变换器的简单方法，该方法将文本和图像标记作为单个数据流进行自回归建模。在足够的数据和规模下，该方法在零样本情况下与之前的领域特定模型具有竞争力。

3. 《Scaling Autoregressive Models for Content-Rich Text-to-Image Generation》一文中，作者提出了Pathways Autoregressive Text-to-Image (Parti)模型，该模型生成高保真度的真实感图像，并支持涉及复杂组合和世界知识的内容丰富的合成。Parti将文本到图像生成视为序列到序列建模问题，并使用ViT-VQGAN对图像进行编码。通过将编码器-解码器变换器模型扩展到200亿参数，实现了一致的质量改进。

这些参考论文在Sora模型训练中的作用主要体现在以下几点：
1. 为图像生成提供了基于变换器架构的方法和技术。
2. 通过自然语言处理技术的启发，为视频生成提供了新的思路。
3. 通过扩展自回归模型，实现了内容丰富的文本到图像生成，为Sora模型的视频生成提供了支持。