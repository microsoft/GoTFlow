这几篇论文的共性主题是基于变换器架构的图像生成和文本到图像生成。

1. 《Generative Pretraining from Pixels》这篇论文探讨了使用序列变换器自回归地预测像素，以学习图像的有用表示。研究发现，即使在低分辨率的ImageNet上进行无标签训练，GPT-2规模的模型也能学习到强大的图像表示。

2. 《Zero-Shot Text-to-Image Generation》这篇论文提出了一种简单的文本到图像生成方法，该方法基于将文本和图像标记作为单个数据流的变换器自回归地建模。在足够的数据和规模下，该方法在零样本情况下与之前的领域特定模型具有竞争力。

3. 《Scaling Autoregressive Models for Content-Rich Text-to-Image Generation》这篇论文提出了Pathways Autoregressive Text-to-Image (Parti)模型，该模型生成高保真度的真实感图像，并支持涉及复杂组合和世界知识的内容丰富的合成。Parti将文本到图像生成视为序列到序列建模问题，并通过扩展数据和模型规模来提高性能。Parti首先使用基于变换器的图像标记器ViT-VQGAN将图像编码为离散标记的序列，然后通过扩展编码器-解码器变换器模型，实现了一致的质量改进。

这些参考论文在Sora模型训练中的作用主要体现在以下几点：
1. 提供了基于变换器架构的图像生成和文本到图像生成的方法和技术。
2. 证明了在大规模数据和模型规模下，这些方法可以学习到强大的图像表示和生成高质量的图像。
3. 为Sora模型提供了在不同任务和应用场景下的有效性和可扩展性的证据。