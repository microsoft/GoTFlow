这几篇论文的共性主题是关于视频数据建模的数据处理，特别是时空补丁的处理。这些论文主要研究了如何利用变换器架构处理图像和视频数据，以提高计算机视觉任务的性能。

第15篇论文提出了一种直接应用于图像补丁序列的纯变换器模型，用于图像分类任务。在大量数据上进行预训练后，该模型在多个中小型图像识别基准上取得了优异的结果，与最先进的卷积网络相比，训练所需的计算资源要少得多。

第16篇论文介绍了一种基于纯变换器的视频分类模型，该模型从输入视频中提取时空标记，然后通过一系列变换器层进行编码。为了处理视频中遇到的长序列标记，作者提出了几种高效的模型变体，对输入的空间和时间维度进行因子分解。通过有效地正则化模型训练并利用预训练的图像模型，该方法在相对较小的数据集上取得了良好的效果。在多个视频分类基准上，该模型超越了基于深度3D卷积网络的先前方法。

第17篇论文展示了遮罩自编码器（MAE）在计算机视觉中的可扩展性。通过开发一种非对称的编码器-解码器架构和遮罩大部分输入图像的策略，作者实现了高效且有效的大模型训练。这种可扩展的方法使得模型具有更好的泛化能力，例如，在仅使用ImageNet-1K数据的方法中，Vanilla ViT-Huge模型达到了最佳准确率（87.8%）。

第18篇论文提出了NaViT（Native Resolution ViT），一种在训练过程中使用序列打包处理任意分辨率和宽高比输入的模型。NaViT在大规模监督和对比图像-文本预训练中表现出改进的训练效率，并在图像和视频分类、目标检测和语义分割等任务中取得了优异的性能。此外，NaViT在鲁棒性和公平性基准上也取得了改进的结果。

综上所述，这些参考论文在Sora模型训练中的作用主要体现在利用变换器架构处理视频和图像的时空补丁，从而在计算机视觉任务中实现高效且有效的模型训练和优异的性能。