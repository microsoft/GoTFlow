这几篇论文的共性主题是关于视频数据建模的数据处理，特别是时空补丁的处理。这些论文主要研究了如何利用变换器架构处理图像和视频数据，以提高计算机视觉任务的性能。

第15篇论文提出了一种直接应用于图像补丁序列的纯变换器，称为视觉变换器（ViT），在图像分类任务上取得了优异的结果。与传统的卷积神经网络相比，ViT在训练时需要更少的计算资源。

第16篇论文介绍了一种基于纯变换器的视频分类模型，该模型从输入视频中提取时空标记，然后通过一系列变换器层进行编码。为了处理视频中遇到的长序列标记，作者提出了几种有效的模型变体，对输入的空间和时间维度进行因子分解。该模型在多个视频分类基准测试（如Kinetics 400和600、Epic Kitchens、Something-Something v2和Moments in Time）上取得了最先进的结果，优于基于深度3D卷积网络的先前方法。

第17篇论文展示了遮罩自编码器（MAE）在计算机视觉中的可扩展性。通过开发一种非对称的编码器-解码器架构和遮罩大部分输入图像（如75%），实现了高效且有效的大模型训练。这种可扩展方法使得学习高容量模型并在下游任务中取得良好泛化性能成为可能。

第18篇论文提出了一种名为NaViT（Native Resolution ViT）的模型，利用序列打包处理任意分辨率和宽高比的输入。NaViT在大规模监督和对比图像-文本预训练中表现出改进的训练效率，并在图像和视频分类、目标检测和语义分割等任务中取得了优异的结果。

这些参考论文在Sora模型训练中的作用主要体现在利用变换器架构处理视频和图像数据，提高模型在计算机视觉任务中的性能。这些研究为Sora模型提供了理论基础和实践经验，使其能够在处理不同时长、分辨率和宽高比的视频和图像数据时生成高质量的视频内容。